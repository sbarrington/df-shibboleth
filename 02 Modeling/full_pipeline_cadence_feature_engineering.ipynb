{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe89e6-15d0-40d4-b3ef-5222c485275a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40233ab1-3364-4058-af97-fa9ed2652b08",
   "metadata": {},
   "source": [
    "# Cadence Feature Extraction Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928c316-2b92-4250-b1cd-a38d5f3eb8f7",
   "metadata": {},
   "source": [
    "# Packages and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac2b3678-c2d5-4d59-a2f1-2d594cb02d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WD: /home/ubuntu/testing-code/cadence-modellling\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import yaml\n",
    "import disvoice\n",
    "import librosa \n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from numpy import diff\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "from pydub import AudioSegment, silence\n",
    "from pydub.playback import play\n",
    "\n",
    "# Configure display and plotting options\n",
    "pd.set_option('display.max_rows', None)\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "# Set WD\n",
    "try:\n",
    "    os.chdir('cadence_modelling/')\n",
    "except:\n",
    "    print(f'WD: {os.getcwd()}')\n",
    "\n",
    "# Import configs\n",
    "with open('/home/ubuntu/configs/config.yaml', 'r') as file:\n",
    "    inputs = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81145b-7a17-44e1-a528-eae0d8625d10",
   "metadata": {},
   "source": [
    "# Ingestion of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34c97b51-ad55-4bc1-97d4-81d981dc839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin with list of files; here we use an example template while we await the full class ouput\n",
    "def extract_input_files(data_input_path):\n",
    "\n",
    "    all_wav_files = pathlib.Path(data_input_path)\n",
    "    all_wav_files = list(all_wav_files.rglob(\"*.wav\")) + list(all_wav_files.rglob(\"*.WAV\"))\n",
    "    all_wav_files = [str(file) for file in all_wav_files]\n",
    "\n",
    "    #real_resampled_wav_files = [file for file in all_wav_files if 'TIMIT converted' in file]\n",
    "    #fake_resampled_wav_files = [file for file in all_wav_files if not 'TIMIT converted' in file]\n",
    "\n",
    "    flags = [1 if 'TIMIT converted' in str(item) else 0 for item in all_wav_files]\n",
    "    \n",
    "    return all_wav_files, flags #real_resampled_wav_files, fake_resampled_wav_files, flags\n",
    "\n",
    "all_wav_files, flags = extract_input_files('../../data/TIMIT-fake')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ce45c5-3973-45c1-83a0-bd62d2370374",
   "metadata": {},
   "source": [
    "# 1. Set thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d36daa05-c713-4511-a1c6-d40e992d4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "silence_threshold = 0.005 # 0.5 percent (0.005), from '0_cadence_modelling.ipynb'. Previously we used 0.2% in the truncation step.\n",
    "low_pass_filter_cutoff = 10 # from '1_cadence_LJ.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1c150-0e33-4868-9065-4bcc85ae4761",
   "metadata": {},
   "source": [
    "# Balance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c149975-8a42-46dc-a5fa-7f403bc7e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO CHECK THIS - does it do it by architecture?\n",
    "def balance_data(all_wav_files):\n",
    "    \n",
    "    folders = set([all_wav_files[i].split('_')[-1].split('.')[0] for i in range(len(all_wav_files))])\n",
    "    \n",
    "    real_resampled_wav_files = [file for file in all_wav_files if 'TIMIT converted' in file]\n",
    "    fake_resampled_wav_files = [file for file in all_wav_files if not 'TIMIT converted' in file]\n",
    "    \n",
    "    # Ensure we take the same number of each phrase for real and fake, downsample the fake files \n",
    "    balanced_real_resampled_wav_files = []\n",
    "    balanced_fake_resampled_wav_files = []\n",
    "    \n",
    "    for folder in folders:\n",
    "        real_examples = [file for file in real_resampled_wav_files if f'_{folder}.' in file]\n",
    "        fake_examples = [file for file in fake_resampled_wav_files if f'_{folder}.' in file]\n",
    "\n",
    "        if len(real_examples) > len(fake_examples):\n",
    "            real_examples = random.sample(real_examples, len(fake_examples))\n",
    "        else:\n",
    "            fake_examples = random.sample(fake_examples, len(real_examples))\n",
    "\n",
    "        [balanced_real_resampled_wav_files.append(file) for file in real_examples]\n",
    "        [balanced_fake_resampled_wav_files.append(file) for file in fake_examples]\n",
    "    \n",
    "    rebalanced_wav_files = balanced_real_resampled_wav_files + balanced_fake_resampled_wav_files\n",
    "    rebalanced_flags = [i for i in np.zeros(len(balanced_real_resampled_wav_files))] + [i for i in np.ones(len(balanced_fake_resampled_wav_files))] \n",
    "    \n",
    "    return rebalanced_wav_files, rebalanced_flags\n",
    "\n",
    "rebalanced_wav_files, rebalanced_flags = balance_data(all_wav_files)\n",
    "\n",
    "# Quick test\n",
    "#print(len(balanced_real_resampled_wav_files), len(balanced_fake_resampled_wav_files))\n",
    "\n",
    "#folders = set([real_resampled_wav_files[i].split('_')[-1].split('.')[0] for i in range(len(real_resampled_wav_files))])\n",
    "\n",
    "#for folder in folders:\n",
    "#    real_fols = [item for item in balanced_real_resampled_wav_files if item.lower().endswith(f'{folder.lower()}.wav')]\n",
    "#    fake_fols = [item for item in balanced_fake_resampled_wav_files if item.lower().endswith(f'{folder.lower()}.wav')]\n",
    "#    if len(real_fols) != len(fake_fols):\n",
    "#           print(len(real_fols), len(fake_fols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8595f90-f891-40b2-b474-60a5c625399b",
   "metadata": {},
   "source": [
    "# 2. Normalise amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d3c9e7-f164-46ec-8428-8389c5c679a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_audio_amplitudes(all_wav_files):\n",
    "    normalized_audios = []\n",
    "    \n",
    "    for file in all_wav_files:\n",
    "        sample = librosa.load(file)[0]\n",
    "        max_abs = np.max(np.abs(sample))\n",
    "        normalized_sample = sample/max_abs\n",
    "        normalized_audios.append(normalized_sample)\n",
    "        \n",
    "    return normalized_audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7400c5f2-6636-4dc1-88b2-12f3d07a9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_audios = normalize_audio_amplitudes(all_wav_files)\n",
    "\n",
    "# Perform check\n",
    "i = 0\n",
    "plt.grid()\n",
    "plt.plot(np.arange(len(normalized_audios[i])), normalized_audios[i])\n",
    "plt.title(f\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8986132e-c15d-4e23-803e-a1cc9417b7b8",
   "metadata": {},
   "source": [
    "# 3. Truncate silences at start and end of clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54004148-b0c7-41cd-9953-122b871d49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_silences(normalized_audios, silence_threshold, window_size=100, counter=0):\n",
    "    truncated_audios = []\n",
    "    start_ids = []\n",
    "    end_ids = []\n",
    "    \n",
    "    for audio in normalized_audios:\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:\n",
    "            print(f'Truncating audio {counter}/{len(normalized_audios)} ({round(counter*100/len(normalized_audios))}%)')\n",
    "\n",
    "        for j in range(len(audio)):\n",
    "            roll_average = np.mean(np.abs(audio[j:j+window_size]))\n",
    "            if roll_average > silence_threshold:\n",
    "                truncation_id_start = j\n",
    "                break\n",
    "\n",
    "        for j in reversed(range(len(audio))):\n",
    "            roll_average = np.mean(np.abs(audio[j-window_size:j]))\n",
    "            if roll_average > silence_threshold:\n",
    "                truncation_id_end = j-window_size\n",
    "                break\n",
    "        truncated_audios.append(audio[truncation_id_start:truncation_id_end])\n",
    "        start_ids.append(truncation_id_start)\n",
    "        end_ids.append(truncation_id_end)\n",
    "    \n",
    "    return truncated_audios, start_ids, end_ids\n",
    "\n",
    "#truncated_audios, start_ids, end_ids = truncate_silences(normalized_audios, silence_threshold, window_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b5c5d-1633-4f0d-a445-9bb4a4861dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "#j = 9770\n",
    "#i = 9782\n",
    "\n",
    "#for item in np.arange(j, i):\n",
    "#    print(item)\n",
    "#    plt.grid()\n",
    "#    plt.plot(np.arange(len(normalized_audios[item])), normalized_audios[item])\n",
    "#    plt.title(f\"\")\n",
    "#    plt.axvline(x=start_ids[item], color='r', linestyle='-')\n",
    "#    plt.axvline(x=end_ids[item], color='r', linestyle='-')\n",
    "#    plt.plot(np.arange(len(truncated_audios[item])), truncated_audios[item])\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b000154-fa74-4d27-bf7b-cfece706f9a1",
   "metadata": {},
   "source": [
    "# 4. Features: Pause Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a2d7085-3b90-4c71-8941-620c9b6388ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "def get_silence(audio, percent, sample_rate=None, cutoff_frequency=None):\n",
    "    thresh = max(abs(audio))*percent\n",
    "    \n",
    "    moving_avg = moving_average(abs(audio), 100)\n",
    "\n",
    "    silent = np.where(abs(moving_avg) < thresh)\n",
    "    voiced = np.where(abs(moving_avg) >= thresh)\n",
    "    \n",
    "    pct_pause = len(silent[0])*100/(len(silent[0])+len(voiced[0]))\n",
    "    pct_voiced = len(voiced[0])*100/(len(silent[0])+len(voiced[0]))\n",
    "    ratio_pause_voiced = len(silent[0])/len(voiced[0]) \n",
    "\n",
    "    return {'pct_pause':pct_pause, 'pct_voiced': pct_voiced, 'ratio_pause_voiced': ratio_pause_voiced}\n",
    "\n",
    "def get_silence_spread(audio, percent, sample_rate=None, cutoff_frequency=None):\n",
    "\n",
    "    thresh = max(abs(audio))*percent\n",
    "    \n",
    "    moving_avg = moving_average(abs(audio), 100)\n",
    "\n",
    "    silent_windows = np.where(moving_avg < thresh)\n",
    "    moving_avg[silent_windows] = 0\n",
    "    silence_count = 0\n",
    "    silence_counts = []\n",
    "    \n",
    "    for i in range(len(moving_avg)-1):\n",
    "        item = moving_avg[i]\n",
    "        next_item = moving_avg[i+1]\n",
    "        \n",
    "        if item != 0 and next_item == 0:\n",
    "            silence_count = 0\n",
    "            \n",
    "        elif item == 0 and next_item == 0:\n",
    "            silence_count += 1\n",
    "            \n",
    "        elif item == 0 and next_item != 0:\n",
    "            silence_counts.append(silence_count)\n",
    "        \n",
    "        else:\n",
    "            continue  \n",
    "    \n",
    "    # Get spreads/means and normalise\n",
    "    spread_of_silences = np.std(silence_counts)/len(moving_avg)\n",
    "    mean_of_silences = np.mean(silence_counts)/len(moving_avg)\n",
    "    n_pauses = len(silence_counts)\n",
    "        \n",
    "    return {'spread_of_silences':spread_of_silences, 'mean_of_silences':mean_of_silences, 'silence_counts':silence_counts, 'n_pauses':n_pauses}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0193bbf5-4c83-4dd8-b15a-1c5f65159201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_files(truncated_audios, flags, function, percent, sample_rate=None, cutoff_frequency=None):\n",
    "    # Instantiate results - r=real, f=fake\n",
    "    r_results = []\n",
    "    f_results = []\n",
    "\n",
    "    real_indices = np.array([int(i) for i in range(len(flags)) if flags[i] == 0])\n",
    "    fake_indices = np.array([int(i) for i in range(len(flags)) if flags[i] != 0])\n",
    "    \n",
    "    real_examples = [truncated_audios[i] for i in real_indices]\n",
    "    fake_examples = [truncated_audios[i] for i in fake_indices]\n",
    "\n",
    "    for item in real_examples:\n",
    "        r_result = function(item, percent, sample_rate, cutoff_frequency)\n",
    "        r_results.append(r_result)\n",
    "\n",
    "    for item in fake_examples:\n",
    "        f_result = function(item, percent, sample_rate, cutoff_frequency)\n",
    "        f_results.append(f_result)\n",
    "    \n",
    "    return r_results, f_results\n",
    "\n",
    "#r_results, f_results = run_all_files(truncated_audios, rebalanced_flags, get_silence, silence_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64def2d5-15a3-4510-b566-f2df5aeeabe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_pauses, f_pauses = run_all_files(truncated_audios, rebalanced_flags, get_silence, silence_threshold)\n",
    "r_silence_spreads, f_silence_spreads = run_all_files(truncated_audios, rebalanced_flags, get_silence_spread, silence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76d6ce-6562-4b5a-a18e-971f031a13df",
   "metadata": {},
   "source": [
    "# Amplitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88544247-1776-4e56-b679-475ec2676aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(audio, sample_rate, cutoff_frequency):\n",
    "    t = np.arange(len(audio)) / sample_rate \n",
    "    w = cutoff_frequency / (sample_rate / 2) \n",
    "    b, a = signal.butter(5, w, 'low')\n",
    "    smoothed_signal = signal.filtfilt(b, a, audio)\n",
    "    \n",
    "    return smoothed_signal\n",
    "\n",
    "def get_amplitude(audio, percent, sample_rate, cutoff_frequency):\n",
    "\n",
    "    abs_audio = abs(audio)\n",
    "    smoothed_signal = filter_signal(abs_audio, sample_rate, cutoff_frequency)\n",
    "    \n",
    "    deriv_amplitude = np.mean(diff(smoothed_signal))\n",
    "    mean_amplitude = np.mean(smoothed_signal)\n",
    "    \n",
    "        \n",
    "    return {'abs_deriv_amplitude':abs(deriv_amplitude), 'mean_amplitude':mean_amplitude}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9490d1f-3feb-4ec7-8282-329ef8fcb575",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = librosa.load(all_wav_files[0])[1]\n",
    "r_amps, f_amps = run_all_files(truncated_audios, rebalanced_flags, get_amplitude, percent=silence_threshold, sample_rate=sr, cutoff_frequency=low_pass_filter_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8612db-c511-4030-a2f8-441feedff22c",
   "metadata": {},
   "source": [
    "# Create features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e4171-a428-427b-80e9-fbe5b0a05dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_amps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc7918-99c0-4560-8ad1-8ded050bfc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_pauses[0]['pct_pause'])\n",
    "print(r_silence_spreads[0])\n",
    "print(r_amps[0])\n",
    "\n",
    "print(len(f_pauses), len(f_silence_spreads), len(f_amps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada3f30a-e46a-4d3d-8d66-477f8bb3d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame({'file': rebalanced_wav_files, \n",
    "                         'pause_ratio':[item['ratio_pause_voiced'] for item in r_pauses + f_pauses], \n",
    "                         'pause_mean':[item['mean_of_silences'] for item in r_silence_spreads + f_silence_spreads], \n",
    "                         'pause_std':[item['spread_of_silences'] for item in r_silence_spreads + f_silence_spreads],  \n",
    "                         'n_pauses':[item['n_pauses'] for item in r_silence_spreads + f_silence_spreads], \n",
    "                         'amp_deriv':[item['abs_deriv_amplitude'] for item in r_amps + f_amps],\n",
    "                         'amp_mean':[item['mean_amplitude'] for item in r_amps + f_amps], \n",
    "                         'fake':rebalanced_flags})\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209913b3-6b23-4377-8b20-633cdc361bf1",
   "metadata": {},
   "source": [
    "# Run full pipeline within single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fd0ab0c-4807-49e4-86d9-33565472d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cadence_feature_extraction_pipeline(data_input_path = '../../data/TIMIT-fake', silence_threshold = 0.005, low_pass_filter_cutoff = 10):\n",
    "    \n",
    "    ## PREPROCESS\n",
    "    # Extract input files\n",
    "    print('Extracting input files')\n",
    "    all_wav_files, all_flags = extract_input_files(data_input_path)\n",
    "    \n",
    "    # Obtain sample rate\n",
    "    sr = librosa.load(all_wav_files[0])[1]\n",
    "    \n",
    "    # Balance data\n",
    "    print('Balancing data')\n",
    "    rebalanced_wav_files, rebalanced_flags = balance_data(all_wav_files)\n",
    "    \n",
    "    # Normalise amplitudes\n",
    "    print('Normalizing amplitudes')\n",
    "    normalized_audios = normalize_audio_amplitudes(rebalanced_wav_files)\n",
    "    \n",
    "    # Truncate silences\n",
    "    print('Truncating silences')\n",
    "    truncated_audios, start_ids, end_ids = truncate_silences(normalized_audios, silence_threshold, window_size=100)\n",
    "    \n",
    "    ## FEATURE ENGINEERING\n",
    "    # Extract pauses \n",
    "    print('Extracting pauses')\n",
    "    r_pauses, f_pauses = run_all_files(truncated_audios, rebalanced_flags, get_silence, silence_threshold)\n",
    "\n",
    "    # Extract pause spreads\n",
    "    print('Extracting pause spreads')\n",
    "    r_silence_spreads, f_silence_spreads = run_all_files(truncated_audios, rebalanced_flags, get_silence_spread, silence_threshold)\n",
    "\n",
    "    # Extract amplitude and derivative\n",
    "    print('Extracting amplitude features')\n",
    "    r_amps, f_amps = run_all_files(truncated_audios, rebalanced_flags, get_amplitude, silence_threshold, sample_rate=sr, cutoff_frequency=low_pass_filter_cutoff)\n",
    "    \n",
    "    ## FEATURE CONSOLIDATION\n",
    "    # Create dataframe \n",
    "    print('Creating dataframe')\n",
    "    features = pd.DataFrame({'file': rebalanced_wav_files, \n",
    "                         'pause_ratio':[item['ratio_pause_voiced'] for item in r_pauses + f_pauses], \n",
    "                         'pause_mean':[item['mean_of_silences'] for item in r_silence_spreads + f_silence_spreads], \n",
    "                         'pause_std':[item['spread_of_silences'] for item in r_silence_spreads + f_silence_spreads],  \n",
    "                         'n_pauses':[item['n_pauses'] for item in r_silence_spreads + f_silence_spreads], \n",
    "                         'amp_deriv':[item['abs_deriv_amplitude'] for item in r_amps + f_amps],\n",
    "                         'amp_mean':[item['mean_amplitude'] for item in r_amps + f_amps], \n",
    "                         'fake':rebalanced_flags})\n",
    "    \n",
    "    \n",
    "    print('Complete')\n",
    "\n",
    "    return features\n",
    "\n",
    "#features = run_cadence_feature_extraction_pipeline(silence_threshold=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b8587e3-63db-442c-bdf4-7093a17945bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>pause_ratio</th>\n",
       "      <th>pause_mean</th>\n",
       "      <th>pause_std</th>\n",
       "      <th>n_pauses</th>\n",
       "      <th>amp_deriv</th>\n",
       "      <th>amp_mean</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/TIMIT-fake/TIMIT converted/wav_file...</td>\n",
       "      <td>0.181783</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006261</td>\n",
       "      <td>49</td>\n",
       "      <td>9.505970e-08</td>\n",
       "      <td>0.048758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/TIMIT-fake/TIMIT converted/wav_file...</td>\n",
       "      <td>0.157594</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>48</td>\n",
       "      <td>5.639012e-07</td>\n",
       "      <td>0.059706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/TIMIT-fake/TIMIT converted/wav_file...</td>\n",
       "      <td>0.202561</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>32</td>\n",
       "      <td>1.488513e-08</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/TIMIT-fake/TIMIT converted/wav_file...</td>\n",
       "      <td>0.091756</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>9</td>\n",
       "      <td>4.684491e-08</td>\n",
       "      <td>0.067209</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/TIMIT-fake/TIMIT converted/wav_file...</td>\n",
       "      <td>0.104823</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>46</td>\n",
       "      <td>3.374259e-07</td>\n",
       "      <td>0.046344</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  pause_ratio  pause_mean  \\\n",
       "0  ../../data/TIMIT-fake/TIMIT converted/wav_file...     0.181783    0.003125   \n",
       "1  ../../data/TIMIT-fake/TIMIT converted/wav_file...     0.157594    0.002825   \n",
       "2  ../../data/TIMIT-fake/TIMIT converted/wav_file...     0.202561    0.004947   \n",
       "3  ../../data/TIMIT-fake/TIMIT converted/wav_file...     0.091756    0.008824   \n",
       "4  ../../data/TIMIT-fake/TIMIT converted/wav_file...     0.104823    0.002049   \n",
       "\n",
       "   pause_std  n_pauses     amp_deriv  amp_mean  fake  \n",
       "0   0.006261        49  9.505970e-08  0.048758   0.0  \n",
       "1   0.006588        48  5.639012e-07  0.059706   0.0  \n",
       "2   0.009044        32  1.488513e-08  0.050680   0.0  \n",
       "3   0.012158         9  4.684491e-08  0.067209   0.0  \n",
       "4   0.003823        46  3.374259e-07  0.046344   0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5c057-61de-4610-a523-92afa094b875",
   "metadata": {},
   "source": [
    "# X. Test on timit non-processed to see if same results arise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a67cf4-66f6-47d3-acad-e01384255a96",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c32ae9ca-2e40-40b7-ab74-81b482c50a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_nans = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9d3010c-889a-4bc2-904e-4f70b6c2d3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5348"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NAs for now \n",
    "nan_indices = features_with_nans[features_with_nans.isna().any(axis=1)].index\n",
    "features = features_with_nans.drop(nan_indices, axis=0)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49453e86-24e1-43eb-962a-be22d1b89561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features.iloc[:, 1:-1], features['fake'], test_size=0.25, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5667ac68-847d-4d70-8e62-11b794d82638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8960359012715033\n",
      "Feature: 0, Score: -6.12156\n",
      "Feature: 1, Score: -1.81311\n",
      "Feature: 2, Score: -3.26143\n",
      "Feature: 3, Score: -0.07837\n",
      "Feature: 4, Score: 1.99840\n",
      "Feature: 5, Score: 14.74101\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_norm, y_train)\n",
    "print(clf.score(X_test_norm, y_test))\n",
    "\n",
    "importance = clf.coef_[0]\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697758d-41e6-46eb-afe8-d2618ced5396",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pause ratio only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa1fd08b-c2c6-45dd-bbd9-aa6d76348880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950635751682872\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features[['pause_ratio']], features['fake'], test_size=0.25, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_norm, y_train)\n",
    "print(clf.score(X_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f34975-2056-41d2-9952-e94724d2f17f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## N Pauses only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93b532ab-783a-4ef8-8740-4ff821a3d3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6866118175018698\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features[['n_pauses']], features['fake'], test_size=0.25, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_norm, y_train)\n",
    "print(clf.score(X_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f4165-b0ba-4402-9fda-c076a5e6fb1c",
   "metadata": {},
   "source": [
    "## Amplitude only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcc026ac-7601-46cb-a802-788885656f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8765893792071803\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features[['amp_mean']], features['fake'], test_size=0.25, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train_norm, y_train)\n",
    "print(clf.score(X_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf07ab1d-29e9-404c-9399-52c9851e9839",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment 8: SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f299c997-e314-4812-80a5-070b2b4f935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020194465220643"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X_train, X_test, y_train, y_test = train_test_split(features.iloc[:, 1:-1], features['fake'], test_size=0.25, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_norm, y_train)\n",
    "clf.score(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "802bd560-a427-4963-a911-783b3fbbe44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.687 total time=   0.3s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.723 total time=   0.3s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.698 total time=   0.3s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.717 total time=   0.3s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.687 total time=   0.3s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.702 total time=   0.3s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.719 total time=   0.3s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.699 total time=   0.3s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.702 total time=   0.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.719 total time=   0.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.696 total time=   0.2s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.719 total time=   0.2s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.707 total time=   0.2s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.717 total time=   0.3s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.714 total time=   0.2s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.3s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.703 total time=   0.3s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.698 total time=   0.3s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.707 total time=   0.3s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.698 total time=   0.3s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.746 total time=   0.3s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.734 total time=   0.3s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.743 total time=   0.3s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.743 total time=   0.3s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.697 total time=   0.2s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.718 total time=   0.2s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.708 total time=   0.3s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.734 total time=   0.2s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.719 total time=   0.3s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.700 total time=   0.3s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.716 total time=   0.3s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.704 total time=   0.3s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.723 total time=   0.3s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.696 total time=   0.3s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.719 total time=   0.3s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.707 total time=   0.3s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.717 total time=   0.3s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.689 total time=   0.3s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.717 total time=   0.3s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.701 total time=   0.3s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.713 total time=   0.3s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.712 total time=   0.3s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.822 total time=   0.2s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.838 total time=   0.2s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.848 total time=   0.2s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.845 total time=   0.3s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.850 total time=   0.2s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.777 total time=   0.2s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.800 total time=   0.2s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.807 total time=   0.3s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.807 total time=   0.2s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.812 total time=   0.2s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.717 total time=   0.3s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.748 total time=   0.3s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.731 total time=   0.3s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.761 total time=   0.3s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.744 total time=   0.3s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.705 total time=   0.3s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.732 total time=   0.3s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.713 total time=   0.3s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.737 total time=   0.3s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.724 total time=   0.3s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.700 total time=   0.3s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.716 total time=   0.3s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.702 total time=   0.3s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.721 total time=   0.3s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.714 total time=   0.3s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.888 total time=   0.2s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.888 total time=   0.2s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.890 total time=   0.2s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.882 total time=   0.2s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.898 total time=   0.2s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.878 total time=   0.2s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.869 total time=   0.2s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.898 total time=   0.2s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.879 total time=   0.2s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.889 total time=   0.2s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.841 total time=   0.3s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.844 total time=   0.3s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.848 total time=   0.3s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.845 total time=   0.3s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.862 total time=   0.3s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.758 total time=   0.3s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.776 total time=   0.3s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.773 total time=   0.3s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.783 total time=   0.3s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.783 total time=   0.3s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.707 total time=   0.3s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.738 total time=   0.3s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.722 total time=   0.3s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.747 total time=   0.3s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.733 total time=   0.3s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.894 total time=   0.2s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.890 total time=   0.2s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.890 total time=   0.2s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.877 total time=   0.2s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.892 total time=   0.2s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.892 total time=   0.4s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.897 total time=   0.4s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.914 total time=   0.3s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.880 total time=   0.4s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.895 total time=   0.4s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.3s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.894 total time=   0.3s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.906 total time=   0.3s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.893 total time=   0.3s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.901 total time=   0.3s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.869 total time=   0.3s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.3s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.888 total time=   0.3s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.870 total time=   0.3s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.885 total time=   0.3s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.786 total time=   0.3s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.794 total time=   0.4s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.808 total time=   0.3s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.802 total time=   0.3s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.808 total time=   0.3s\n",
      "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=1000, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "  \n",
    "grid = GridSearchCV(clf, param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "  \n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e04eb81-6e51-4730-be28-8f9ef440a323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020194465220643"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=1000, gamma=0.1, kernel='rbf')\n",
    "clf.fit(X_train_norm, y_train)\n",
    "clf.score(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5146c00c-fe6c-4ffd-9371-9ebbaf9e4927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.9041697147037308"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, f1_score\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, X_test_norm, y_test)\n",
    "plt.show()\n",
    "\n",
    "y_pred = clf.predict(X_test_norm)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a581d-3240-49bd-b62d-c983079fa497",
   "metadata": {},
   "source": [
    "# In the wild test\n",
    "https://www.reddit.com/r/ElevenLabs/comments/122wrs0/biden_addresses_the_growing_skooma_use_in_skyrim/\n",
    "\n",
    "Via TubeRipper https://tuberipper.com/279/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f853f86-45b1-41b0-8aac-790af0c87b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting input files\n",
      "Normalizing amplitudes\n",
      "Truncating silences\n",
      "Extracting pauses\n",
      "Extracting pause spreads\n",
      "Extracting amplitude features\n",
      "Creating dataframe\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "def run_cadence_test(data_input_path, flags = [1], silence_threshold = 0.005, low_pass_filter_cutoff = 10):\n",
    "    \n",
    "    ## PREPROCESS\n",
    "    # Extract input files\n",
    "    print('Extracting input files')\n",
    "    all_wav_files, _ = extract_input_files(data_input_path)\n",
    "    \n",
    "    # Obtain sample rate\n",
    "    sr = librosa.load(all_wav_files[0])[1]\n",
    "    \n",
    "    # Normalise amplitudes\n",
    "    print('Normalizing amplitudes')\n",
    "    normalized_audios = normalize_audio_amplitudes(all_wav_files)\n",
    "    \n",
    "    # Truncate silences\n",
    "    print('Truncating silences')\n",
    "    truncated_audios, start_ids, end_ids = truncate_silences(normalized_audios, silence_threshold, window_size=100)\n",
    "    \n",
    "    ## FEATURE ENGINEERING\n",
    "    # Extract pauses \n",
    "    print('Extracting pauses')\n",
    "    r_pauses, f_pauses = run_all_files(truncated_audios, flags, get_silence, silence_threshold)\n",
    "\n",
    "    # Extract pause spreads\n",
    "    print('Extracting pause spreads')\n",
    "    r_silence_spreads, f_silence_spreads = run_all_files(truncated_audios, flags, get_silence_spread, silence_threshold)\n",
    "\n",
    "    # Extract amplitude and derivative\n",
    "    print('Extracting amplitude features')\n",
    "    r_amps, f_amps = run_all_files(truncated_audios, flags, get_amplitude, silence_threshold, sample_rate=sr, cutoff_frequency=low_pass_filter_cutoff)\n",
    "    \n",
    "    ## FEATURE CONSOLIDATION\n",
    "    # Create dataframe \n",
    "    print('Creating dataframe')\n",
    "    features = pd.DataFrame({'file': all_wav_files, \n",
    "                         'pause_ratio':[item['ratio_pause_voiced'] for item in r_pauses + f_pauses], \n",
    "                         'pause_mean':[item['mean_of_silences'] for item in r_silence_spreads + f_silence_spreads], \n",
    "                         'pause_std':[item['spread_of_silences'] for item in r_silence_spreads + f_silence_spreads],  \n",
    "                         'n_pauses':[item['n_pauses'] for item in r_silence_spreads + f_silence_spreads], \n",
    "                         'amp_deriv':[item['abs_deriv_amplitude'] for item in r_amps + f_amps],\n",
    "                         'amp_mean':[item['mean_amplitude'] for item in r_amps + f_amps], \n",
    "                         'fake':flags})\n",
    "    \n",
    "    \n",
    "    print('Complete')\n",
    "\n",
    "    return features\n",
    "\n",
    "test_features = run_cadence_test('test_biden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5a4b2f4e-6b8f-49d4-bfc0-d1bf89d13096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>pause_ratio</th>\n",
       "      <th>pause_mean</th>\n",
       "      <th>pause_std</th>\n",
       "      <th>n_pauses</th>\n",
       "      <th>amp_deriv</th>\n",
       "      <th>amp_mean</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_biden/test_biden_audacity.wav</td>\n",
       "      <td>0.034836</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.00616</td>\n",
       "      <td>8</td>\n",
       "      <td>5.421684e-07</td>\n",
       "      <td>0.133689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file  pause_ratio  pause_mean  pause_std  \\\n",
       "0  test_biden/test_biden_audacity.wav     0.034836    0.004196    0.00616   \n",
       "\n",
       "   n_pauses     amp_deriv  amp_mean  fake  \n",
       "0         8  5.421684e-07  0.133689     1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ccf02622-0506-4988-9ecd-fdda0dc6df8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020194465220643"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "X_train, X_test, y_train, y_test = train_test_split(features.iloc[:, 1:-1], features['fake'], test_size=0.25, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "clf = svm.SVC(C=1000, gamma=0.1, kernel='rbf')\n",
    "clf.fit(X_train_norm, y_train)\n",
    "clf.score(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88e153ba-70ab-4add-a775-60965c361f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pause_ratio  pause_mean  pause_std  n_pauses     amp_deriv  amp_mean\n",
      "0     0.034836    0.004196    0.00616         8  5.421684e-07  0.133689\n",
      "0    1\n",
      "Name: fake, dtype: int64\n",
      "[[0.02884095 0.06504496 0.07353143 0.04117647 0.04992784 0.6368496 ]]\n"
     ]
    }
   ],
   "source": [
    "X_new = test_features.iloc[:, 1:-1]\n",
    "y_new = test_features['fake']\n",
    "print(X_new)\n",
    "print(y_new)\n",
    "\n",
    "X_new_norm = scaler.transform(X_new)\n",
    "print(X_new_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dae84685-ffdb-40f7-8aa5-e30bb10dcd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_wild = clf.predict(X_new_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "539aae97-53d5-4184-b8b4-03529f5349fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_wild"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cadence-modelling",
   "language": "python",
   "name": "cadence-modelling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
